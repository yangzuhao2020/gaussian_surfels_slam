**configs/data/c3vd.yaml**

    dataset_name: 'c3vd'
    camera_params:
    image_height: 540 
    image_width: 675 # 相机分辨率
    fx: 401.1595 # 相机焦距
    fy: 400.9425
    cx: 334.143 # 中心点坐标。
    cy: 273.8665
    png_depth_scale: 2.55 # 深度图表示深度的缩放系数。
    crop_edge: 0
    有了以上信息便可以得到相机内参矩阵。

1. 初始化 3dgs 生成一组高斯点，包括颜色、位置、半径、不透明度等参数。
    太亮的点并不会生成3D 高斯点。

2. tracking: 渲染当前图像、深度、可见性，使用梯度下降优化相机位姿，实现相机轨迹的追踪。
    这里会采用过滤器来排除亮度不可靠的像素，提高追踪的精度。

3. 3Dgs拓展：当观察到新的区域，高斯表示会扩展，这一扩展过程基于3个基本原则，重新投影和转换添加新的高斯，类似于初始化，但针对当前观察进行定制。
    部分精炼：为提高效率，每第 k 帧被指定为关键帧。基于与当前帧的空间和时间接近度的概率分布决定了使用哪些关键帧进行细化。使用可微分光栅化技术将更新的高斯集实时渲染为图像和深度图，从而实现基于梯度的优化。

评估： 使用诸如 PSNR（表示图像质量）、RMSE（表示深度精度）和 ATE（表示 C3VD 数据集上的跟踪精度）等指标来评估性能。

注意的地方：得到的旋转矩阵 一定要想一想是否需要归一化呢？
同时，我们在训练的时候，是先tracking 再 mapping 原因在于 tracking 可以获得相对正确的位姿， 可以减少mapping 损失。

densify_dataset 用于稠密化（Densification），即增强点云的密度。
这是因为 密集点云和初始点云可能需要不同的相机参数，或者需要从更高分辨率的 RGB-D 数据进行提取。
